"""
Tanuki Code Reviewer Agent

Specialized agent for adversarial code review and quality assurance.
This agent provides critical analysis and improvement suggestions
for code generated by other agents.
"""

from typing import Dict, Any, List, Optional
from src.core.base import BaseAgent, AgentType


class TanukiCodeReviewer(BaseAgent):
    """
    Expert agent for code review and quality assurance.
    
    Capabilities:
    - Adversarial review of generated code
    - Code quality assessment
    - Security vulnerability detection
    - Performance bottleneck identification
    - Best practices verification
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize the code reviewer agent."""
        super().__init__(
            agent_name="tanuki-code-reviewer",
            agent_type=AgentType.CORE_PYTHON,
            config=config or {}
        )
        
    def execute(self, task: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute a code review task.
        
        Args:
            task: Review task including code to review and criteria
            context: Project context and review standards
            
        Returns:
            Comprehensive review results with suggestions
        """
        task_type = task.get("type", "review")
        code_to_review = task.get("content", {}).get("generated_code", "")
        original_task = task.get("content", {})
        
        try:
            if task_type == "review":
                return self._perform_code_review(code_to_review, original_task, context)
            elif task_type == "security_review":
                return self._security_review(code_to_review, context)
            elif task_type == "performance_review":
                return self._performance_review(code_to_review, context)
            else:
                return self._general_review(code_to_review, context)
                
        except Exception as e:
            self.logger.error(f"Error in code review: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "agent": self.agent_name
            }
    
    def _perform_code_review(self, code: str, original_task: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """Perform comprehensive code review."""
        review_results = {
            "correctness": self._check_correctness(code, original_task),
            "quality": self._assess_quality(code),
            "security": self._check_security_issues(code),
            "performance": self._check_performance_issues(code),
            "maintainability": self._assess_maintainability(code),
            "best_practices": self._check_best_practices(code)
        }
        
        # Calculate overall score
        overall_score = self._calculate_overall_score(review_results)
        
        # Generate improvement suggestions
        suggestions = self._generate_improvement_suggestions(review_results, code)
        
        # Determine if code should be accepted or needs revision
        approval_status = self._determine_approval_status(overall_score, review_results)
        
        return {
            "status": "completed",
            "agent": self.agent_name,
            "review_results": review_results,
            "overall_score": overall_score,
            "approval_status": approval_status,
            "improvement_suggestions": suggestions,
            "critical_issues": self._identify_critical_issues(review_results)
        }
    
    def _check_correctness(self, code: str, original_task: Dict[str, Any]) -> Dict[str, Any]:
        """Check if code correctly implements the requirements."""
        issues = []
        score = 85  # Base score
        
        # Basic checks
        if len(code.strip()) < 10:
            issues.append("Code appears incomplete")
            score -= 30
        
        return {"score": max(0, score), "issues": issues}
    
    def _assess_quality(self, code: str) -> Dict[str, Any]:
        """Assess overall code quality."""
        issues = []
        score = 90
        
        if '"""' not in code:
            issues.append("Missing docstrings")
            score -= 10
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_security_issues(self, code: str) -> Dict[str, Any]:
        """Check for security vulnerabilities."""
        issues = []
        score = 95
        
        dangerous_patterns = ['eval(', 'exec(', 'os.system(']
        for pattern in dangerous_patterns:
            if pattern in code:
                issues.append(f"Dangerous function: {pattern}")
                score -= 20
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_performance_issues(self, code: str) -> Dict[str, Any]:
        """Check for performance issues."""
        issues = []
        score = 85
        
        if 'for ' in code and 'append(' in code:
            issues.append("Consider list comprehension")
            score -= 10
        
        return {"score": max(0, score), "issues": issues}
    
    def _assess_maintainability(self, code: str) -> Dict[str, Any]:
        """Assess code maintainability."""
        issues = []
        score = 80
        
        lines = len(code.split('\n'))
        if lines > 50:
            issues.append("Code is quite long")
            score -= 15
        
        return {"score": max(0, score), "issues": issues}
    
    def _check_best_practices(self, code: str) -> Dict[str, Any]:
        """Check adherence to Python best practices."""
        issues = []
        score = 85
        
        if 'def ' in code and '->' not in code:
            issues.append("Consider adding type hints")
            score -= 10
        
        return {"score": max(0, score), "issues": issues}
    
    def get_capabilities(self) -> List[str]:
        """Get list of capabilities this agent can handle."""
        return [
            "code_review",
            "quality_assessment",
            "security_analysis",
            "performance_analysis",
            "maintainability_assessment",
            "best_practices_checking"
        ]
    
    def get_required_tools(self) -> List[str]:
        """Get list of tools this agent requires."""
        return [
            "read_file",
            "static_analysis",
            "security_scan",
            "performance_profiler",
            "lint_code"
        ]
    
    # Helper methods
    def _calculate_overall_score(self, review_results: Dict[str, Any]) -> int:
        """Calculate overall review score."""
        scores = []
        for result in review_results.values():
            if isinstance(result, dict) and 'score' in result:
                scores.append(result['score'])
        return int(sum(scores) / len(scores)) if scores else 0
    
    def _generate_improvement_suggestions(self, review_results: Dict[str, Any], code: str) -> List[str]:
        """Generate specific improvement suggestions."""
        suggestions = []
        for result in review_results.values():
            if isinstance(result, dict) and 'issues' in result:
                suggestions.extend(result['issues'])
        return suggestions
    
    def _determine_approval_status(self, overall_score: int, review_results: Dict[str, Any]) -> str:
        """Determine if code should be approved."""
        if overall_score >= 80:
            return "approved"
        elif overall_score >= 60:
            return "approved_with_suggestions"
        else:
            return "needs_revision"
    
    def _identify_critical_issues(self, review_results: Dict[str, Any]) -> List[str]:
        """Identify critical issues that block approval."""
        critical = []
        security = review_results.get("security", {})
        if security.get("score", 100) < 70:
            critical.extend(security.get("issues", []))
        return critical
    
    def _security_review(self, code: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Focused security review."""
        return self._check_security_issues(code)
    
    def _performance_review(self, code: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Focused performance review."""
        return self._check_performance_issues(code)
    
    def _general_review(self, code: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """General code review."""
        return {
            "status": "completed",
            "agent": self.agent_name,
            "review_type": "general",
            "summary": "General review completed"
        } 